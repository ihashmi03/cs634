---
title:  Things to pay attention to after Lecture 4/5 - Linear Classification
date: 2019-02-28
author: Pantelis Monogioudis
tags:
  [
    "cs634",
  ]
excerpt: This is a short list of things to pay attention with respect to Linear Classification. 
draft: false
cover: ./images/circular-dataset.png
publishedAt: here.
canonicalLink:
image: ./images/circular-dataset.png
avatar: avatars/lekoarts.png
imageAuthor: 
imageAuthorLink: 
imageTitle: Classification
showImageInArticle: true
---

We focused on three concepts in the class.

1. With respect to what is linear classification you need to be able to write down the parametric form of a discriminant function whose simplest form is a line / plane. You also need to be able to be able to tell if one is giving you a dataset, using the Bayes rule terminology to distinguish what are the distributions involved (class conditional), prior etc.
2. With respect to classifier performance you need to memorize the 4 performance metrics (TP, FP, etc.) and be able to intuitively explain what each metric is giving you that can help you gauge the quality of classifiers in the ROC curve. 
3. On the perceptron algorithm you need to be able to explain its architecture, what is an activation function and activation and what the non-linearity g(a) is providing.  Finally you need to understand its disadvantages with respect to linerly non-separable datasets.
4. On logistic regression you need to be able to understand why we selected a logistic function in its architecture and this specific non-linearity it provides relative to the others such as the perceptron. 

